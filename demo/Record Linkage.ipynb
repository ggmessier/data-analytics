{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record Linkage\n",
    "A demo of the excellent [Record Linkage](https://recordlinkage.readthedocs.io/en/latest/) toolkit specific to the challenges expected when merging health, police and emergency shelter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import recordlinkage as rl\n",
    "from recordlinkage.datasets import load_febrl2, load_febrl4, binary_vectors\n",
    "from recordlinkage.index import Block, Full, Random\n",
    "from recordlinkage.base import BaseIndexAlgorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Databases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Freely Extensible Biomedical Record Linkage (Febrl) datasets.\n",
    "- `febrl4` contains two tables, A and B, with 5000 entries.\n",
    "- Table A has the original records and Table B contains duplicates.\n",
    "- Used to test merging two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfA, dfB = load_febrl4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "given_name               emma\n",
       "surname                  geue\n",
       "street_number            1220\n",
       "address_1        rumker place\n",
       "address_2          milbrodale\n",
       "suburb                woodend\n",
       "postcode                 2429\n",
       "state                     nsw\n",
       "date_of_birth        19941224\n",
       "soc_sec_id            3886398\n",
       "Name: rec-712-org, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfA.loc['rec-712-org']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "given_name               emam\n",
       "surname                  geue\n",
       "street_number            1220\n",
       "address_1        rumker place\n",
       "address_2          milbrodale\n",
       "suburb                woodend\n",
       "postcode                 2429\n",
       "state                     nsw\n",
       "date_of_birth        19941224\n",
       "soc_sec_id            3886398\n",
       "Name: rec-712-dup-0, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfB.loc['rec-712-dup-0']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- These utilities determine which records should be compared with which other records.\n",
    "- If we're linking two datasets, A and B, every record from A should be compared with B.\n",
    "- If we're looking for redundancies in a single dataset, A, each record in A should be compared with all the records with higher index values.\n",
    "\n",
    "#### Algorithms\n",
    "- **Full:** Pulls out all possible indices.\n",
    "  + Desirable but something to think about.  If AHS has 200,000 individuals and CPS has 5,000 individuals, we have a billion comparisons to do.  Possible but not on laptops or windows PCs.\n",
    "- **Block:** Create pairs that agree on one or more variables (ie. if we only expected variation in first names, we could compare only those records that matched on last name)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Birth Year Blocking\n",
    "- Full indexing for this dataset would be 25e6 entries.  \n",
    "- Block to compare only those records with birth years within 5 years of each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirthYearBlocking(BaseIndexAlgorithm):\n",
    "    \"\"\"Block index based birth years.\"\"\"\n",
    "\n",
    "    def __init__(self,maxYearDiff):\n",
    "        self.maxYearDiff = maxYearDiff\n",
    "        super().__init__()\n",
    "    \n",
    "    \n",
    "    def _link_index(self, df_a, df_b):\n",
    "        \"\"\"Pair records with birth years within self.maxYearDiff of each other.\"\"\"\n",
    "        \n",
    "        birthYearA = df_a['date_of_birth'].str[:4].astype(float)\n",
    "        birthYearB = df_b['date_of_birth'].str[:4].astype(float)\n",
    "\n",
    "        tBar = tqdm(total = len(birthYearA)*len(birthYearB))\n",
    "        tuples = []\n",
    "        for idxA, valA in birthYearA.items():\n",
    "            for idxB, valB in birthYearB.items():\n",
    "                if np.abs(valA-valB) <= self.maxYearDiff:\n",
    "                    tuples += [ (idxA,idxB) ]\n",
    "                tBar.update()\n",
    "\n",
    "        tBar.close()\n",
    "\n",
    "        return pd.MultiIndex.from_tuples(tuples,names=[ df_a.index.name+'_A', df_b.index.name+'_B' ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1a41d9baa94127b034f4cbe06acf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "indexerBlock = BirthYearBlocking(maxYearDiff=5)\n",
    "pairsBlock = indexerBlock.index(dfA,dfB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n",
      "WARNING:recordlinkage:indexing - performance warning - A full index can result in large number of record pairs.\n"
     ]
    }
   ],
   "source": [
    "indexerFull = rl.Index()\n",
    "indexerFull.add(Full())\n",
    "indexerFull.add(Full())\n",
    "pairsFull = indexerFull.index(dfA,dfB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It's possible to compare each field in the databases using different methods (ie. exact matches, string distance metrics, etc.).\n",
    "- The available metrics are from the jellyfish string matching library.  They include Levenshtein, Jaro-Winkler, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.48 s, sys: 1.65 s, total: 4.14 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "comparer = rl.Compare(n_jobs=-1)\n",
    "\n",
    "comparer.string('given_name', 'given_name', method='damerau_levenshtein', label='given_name')\n",
    "comparer.string('surname', 'surname', method='damerau_levenshtein', label='surname')\n",
    "comparer.string('date_of_birth', 'date_of_birth', method='damerau_levenshtein', label='date_of_birth')\n",
    "\n",
    "metricTbl = comparer.compute(pairsFull, dfA, dfB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>date_of_birth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id_1</th>\n",
       "      <th>rec_id_2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rec-1070-org</th>\n",
       "      <th>rec-561-dup-0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2642-dup-0</th>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-608-dup-0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3239-dup-0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-2886-dup-0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">rec-66-org</th>\n",
       "      <th>rec-4495-dup-0</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4211-dup-0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3131-dup-0</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3815-dup-0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-493-dup-0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25000000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             given_name   surname  date_of_birth\n",
       "rec_id_1     rec_id_2                                           \n",
       "rec-1070-org rec-561-dup-0     0.000000  0.000000          0.625\n",
       "             rec-2642-dup-0    0.625000  0.285714          0.375\n",
       "             rec-608-dup-0     0.000000  0.000000          0.375\n",
       "             rec-3239-dup-0    0.000000  0.142857          0.250\n",
       "             rec-2886-dup-0    0.000000  0.111111          0.500\n",
       "...                                 ...       ...            ...\n",
       "rec-66-org   rec-4495-dup-0    0.166667  0.222222          0.625\n",
       "             rec-4211-dup-0    0.000000  0.111111          0.500\n",
       "             rec-3131-dup-0    0.166667  0.000000          0.500\n",
       "             rec-3815-dup-0    0.000000  0.111111          0.625\n",
       "             rec-493-dup-0     0.000000  0.111111          0.375\n",
       "\n",
       "[25000000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metricTbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ideally, we would have a known set of matches (ie. manually matched, linked with health card numbers, etc.).  Supervised learning algorithms can be applied in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Normalize data features.\n",
    "metrics = metricTbl.to_numpy()\n",
    "for r in range(metrics.shape[1]):\n",
    "    metrics[:,r] *= (metrics[:,r] - np.mean(metrics[:,r]))/np.sqrt(np.var(metrics[:,r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of confirmed matches.\n",
    "pat = r'rec-\\d+'\n",
    "match = np.zeros(len(metricTbl.index))\n",
    "iMatch = 0\n",
    "\n",
    "for keys in list(metricTbl.index):\n",
    "    \n",
    "    matchA = re.search(pat,keys[0])\n",
    "    matchB = re.search(pat,keys[1])\n",
    "    \n",
    "    match[iMatch] = 1*( matchA.group(0) == matchB.group(0) )\n",
    "    iMatch += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize logistic regression to match records.\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determines confusion matrix\n",
    "def calc_confusion_matrix(hat,labels):\n",
    "    \n",
    "    tPos = int( np.sum(hat * labels) )\n",
    "    fPos = int( np.sum(hat * (1-labels)) )\n",
    "    pos = int( np.sum(labels) )\n",
    "    neg = len(labels) - pos\n",
    "    fNeg = pos - tPos\n",
    "    tNeg = neg - fPos\n",
    "\n",
    "    return np.array([ [ tPos, fNeg ], [ fPos, tNeg ] ])  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc57fb2867e4e96a547d643d1b8a1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tPos: 4207/5000, fPos: 151/5000\n",
      "tNeg: 24994849/24995000, fNeg: 793/24995000\n",
      "\n",
      "True Positive Rate/Sensitivity: 84.14% (4207/5000)\n",
      "Confidence/Precision: 96.54% (4207/4358)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate using k-fold cross-validation.\n",
    "nFolds = 10\n",
    "\n",
    "skf = StratifiedKFold(n_splits=nFolds, random_state=None, shuffle=True)\n",
    "cnfMtx = np.zeros((2,2),dtype=int)\n",
    "tBar = tqdm(total=nFolds)\n",
    "\n",
    "for trainIdx, testIdx in skf.split(metrics,match):\n",
    "    \n",
    "    lr.fit(metrics[trainIdx,:],match[trainIdx])\n",
    "    hat = lr.predict(metrics[testIdx,:])\n",
    "    cnfMtx += calc_confusion_matrix(hat,match[testIdx])\n",
    "    \n",
    "    tBar.update()\n",
    "    \n",
    "tBar.close()\n",
    "\n",
    "tPos = cnfMtx[0,0]\n",
    "fNeg = cnfMtx[0,1]\n",
    "nPos = tPos+fNeg\n",
    "\n",
    "fPos = cnfMtx[1,0]\n",
    "tNeg = cnfMtx[1,1]\n",
    "nNeg = fPos+tNeg\n",
    "\n",
    "print(f'tPos: {tPos}/{nPos}, fPos: {fPos}/{nPos}')\n",
    "print(f'tNeg: {tNeg}/{nNeg}, fNeg: {fNeg}/{nNeg}\\n')\n",
    "\n",
    "print(f'True Positive Rate/Sensitivity: {100*tPos/nPos:.2f}% ({tPos}/{nPos})')\n",
    "print(f'Confidence/Precision: {100*tPos/(tPos+fPos):.2f}% ({tPos}/{tPos+fPos})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.11384083, 1.0118575 , 3.3772084 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
